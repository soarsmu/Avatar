# -*- coding: utf-8 -*-
"""
MIT Licence
"""
import json
import numpy as np
from keras import backend as K
# from keras.engine.topology import Layer
from keras.initializers import RandomUniform, Initializer, Constant
from keras.layers import Activation, Layer
from keras.layers.core import Dense
from keras.models import Sequential
from sklearn.preprocessing import StandardScaler


class InitCentersRandom(Initializer):
    """ Initializer for initialization of centers of RBF network
        as random samples from the given data set.
    # Arguments
        X: matrix, dataset to choose the centers from (random rows
          are taken as centers)
    """

    def __init__(self, X):
        self.X = X

    def __call__(self, shape, dtype=None):
        assert shape[1] == self.X.shape[1]
        idx = np.random.randint(self.X.shape[0], size=shape[0])
        return self.X[idx, :]


class RBFLayer(Layer):
    """ Layer of Gaussian RBF units.
    # Example
    ```python
        model = Sequential()
        model.add(RBFLayer(10,
                           initializer=InitCentersRandom(X),
                           betas=1.0,
                           input_shape=(1,)))
        model.add(Dense(1))
    ```
    # Arguments
        output_dim: number of hidden units (i.e. number of outputs of the
                    layer)
        initializer: instance of initiliazer to initialize centers
        betas: float, initial value for betas
    """

    def __init__(self, output_dim, initializer=None, betas=1.0, **kwargs):
        self.output_dim = output_dim
        self.init_betas = betas
        if not initializer:
            self.initializer = RandomUniform(0.0, 1.0)
        else:
            self.initializer = initializer
        super(RBFLayer, self).__init__(**kwargs)



    def build(self, input_shape):

        self.centers = self.add_weight(name='centers',
                                       shape=(self.output_dim, input_shape[1]),
                                       initializer=self.initializer,
                                       trainable=True)
        self.betas = self.add_weight(name='betas',
                                     shape=(self.output_dim,),
                                     initializer=Constant(
                                         value=self.init_betas),
                                     # initializer='ones',
                                     trainable=True)

        super(RBFLayer, self).build(input_shape)

    def call(self, x):
        C = K.expand_dims(self.centers)
        H = K.transpose(C-K.transpose(x))
        return K.exp(-self.betas * K.sum(H**2, axis=1))

    def gaussian(self, x, mu, sigma):
        return exp(- metrics(mu, x) ** 2 / (2 * sigma ** 2))

    def compute_output_shape(self, input_shape):
        return (input_shape[0], self.output_dim)

    def get_config(self):
        # have to define get_config to be able to use model_from_json
        config = {
            'output_dim': self.output_dim
        }
        base_config = super(RBFLayer, self).get_config()
        return dict(list(base_config.items()) + list(config.items()))

class Model:
    ss = StandardScaler()

    def __init__(self,no_of_neurons,cluster):
        self.train(no_of_neurons,np.array(cluster))

    def train(self,no_of_neurons,cluster):
        # dataset = pd.read_csv(clean_file_name,header=None)
        # for x in cluster:
        #     print(x)
        X = cluster[:, 0:5]
        y = cluster[:, 5]
  
        X = self.ss.fit_transform(X)
        self.model = Sequential()
        rbflayer = RBFLayer(no_of_neurons,
                                initializer=InitCentersRandom(X),
                                betas=3.0,
                                input_shape=(5,))
        self.model.add(rbflayer)
        self.model.add(Dense(1))
        self.model.add(Activation('linear'))
        self.model.compile(loss='mean_absolute_error',
                          optimizer = 'adam')
        self.model.fit(X, y, epochs=1000, batch_size=8, verbose=0)

    def test(self, cluster):
        mae = 0
        for i in range(len(cluster)):
            y_act = cluster[i][5]
            Y_pred = self.predict(cluster[i][:5])

            mae = mae + abs(y_act - Y_pred)
        self.mae = mae / len(cluster)

    def predict(self,val):
        value = np.array([val])
        B = self.ss.transform(value)
        y_pred = self.model.predict([B], verbose=0)
        # print(y_pred)
        return y_pred

if __name__ == "__main__":
    data = []
    with open("surrogate_acc.jsonl") as f:
        for line in f:
            data.append(json.loads(line.strip()))
    
    cluster = []

    for d in data:
        temp = []
        for c in d.values():
            temp.append(c)
        cluster.append(temp)

    pre = Model(10,cluster)

    pre.test(cluster)

    print(pre.predict([45000, 8, 16, 496, 1]))
